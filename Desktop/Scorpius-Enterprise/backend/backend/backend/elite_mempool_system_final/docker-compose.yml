version: '3.8'

services:
  # ==================== INFRASTRUCTURE ====================
  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    healthcheck:
      test: ["CMD", "bash", "-c", "echo ruok | nc localhost 2181"]
      interval: 10s
      timeout: 5s
      retries: 5

  kafka:
    image: confluentinc/cp-kafka:7.4.0
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "9092:9092"
      - "29092:29092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    healthcheck:
      test: ["CMD", "kafka-topics", "--list", "--bootstrap-server", "localhost:9092"]
      interval: 30s
      timeout: 10s
      retries: 3

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    depends_on:
      kafka:
        condition: service_healthy
    ports:
      - "8080:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:29092

  postgres:
    image: postgres:15-alpine
    ports:
      - "5432:5432"
    environment:
      POSTGRES_DB: scorpius_elite
      POSTGRES_USER: scorpius
      POSTGRES_PASSWORD: elite_password_123
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./infrastructure/postgres/init.sql:/docker-entrypoint-initdb.d/init.sql
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U scorpius -d scorpius_elite"]
      interval: 5s
      timeout: 5s
      retries: 5

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    command: redis-server --appendonly yes
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 5

  clickhouse:
    image: clickhouse/clickhouse-server:23.8
    ports:
      - "8123:8123"
      - "9000:9000"
    environment:
      CLICKHOUSE_DB: scorpius_analytics
      CLICKHOUSE_USER: analytics
      CLICKHOUSE_PASSWORD: clickhouse_password_123
    volumes:
      - clickhouse_data:/var/lib/clickhouse
      - ./infrastructure/clickhouse/init.sql:/docker-entrypoint-initdb.d/init.sql
    healthcheck:
      test: ["CMD", "clickhouse-client", "--query", "SELECT 1"]
      interval: 30s
      timeout: 10s
      retries: 3

  # ==================== CORE SERVICES ====================
  ingestion:
    build:
      context: ./services/ingestion
      dockerfile: Dockerfile
    depends_on:
      kafka:
        condition: service_healthy
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    environment:
      KAFKA_BROKERS: kafka:29092
      POSTGRES_URL: postgres://scorpius:elite_password_123@postgres:5432/scorpius_elite
      REDIS_URL: redis://redis:6379
      LOG_LEVEL: info
      CHAIN_ENDPOINTS: |
        {
          "ethereum": ["wss://eth-mainnet.ws.alchemyapi.io/v2/${ALCHEMY_API_KEY}", "wss://mainnet.infura.io/ws/v3/${INFURA_PROJECT_ID}"],
          "arbitrum": ["wss://arb-mainnet.ws.alchemyapi.io/v2/${ALCHEMY_API_KEY}"],
          "optimism": ["wss://opt-mainnet.ws.alchemyapi.io/v2/${ALCHEMY_API_KEY}"],
          "base": ["wss://base-mainnet.ws.alchemyapi.io/v2/${ALCHEMY_API_KEY}"]
        }
    restart: unless-stopped

  rule-engine:
    build:
      context: ./services/rule_engine
      dockerfile: Dockerfile
    depends_on:
      kafka:
        condition: service_healthy
      postgres:
        condition: service_healthy
    environment:
      KAFKA_BROKERS: kafka:29092
      POSTGRES_URL: postgres://scorpius:elite_password_123@postgres:5432/scorpius_elite
      LOG_LEVEL: info
      WASM_CACHE_SIZE: 1000
      MAX_CONCURRENT_RULES: 10000
    restart: unless-stopped

  api:
    build:
      context: ./services/api
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      kafka:
        condition: service_healthy
    environment:
      DATABASE_URL: postgres://scorpius:elite_password_123@postgres:5432/scorpius_elite
      REDIS_URL: redis://redis:6379
      KAFKA_BROKERS: kafka:29092
      SECRET_KEY: ${SECRET_KEY:-super_secret_key_change_in_production}
      ENVIRONMENT: development
      CORS_ORIGINS: http://localhost:3000,http://localhost:3001
    restart: unless-stopped

  frontend:
    build:
      context: ./services/frontend
      dockerfile: Dockerfile
    ports:
      - "3000:3000"
    environment:
      NEXT_PUBLIC_API_URL: http://localhost:8000
      NEXT_PUBLIC_WS_URL: ws://localhost:8000
      NODE_ENV: development
    depends_on:
      - api
    restart: unless-stopped

  notifier:
    build:
      context: ./services/notifier
      dockerfile: Dockerfile
    depends_on:
      kafka:
        condition: service_healthy
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    environment:
      KAFKA_BROKERS: kafka:29092
      KAFKA_INPUT_TOPIC: alerts
      KAFKA_CONSUMER_GROUP: notifier-service
      POSTGRES_URL: postgres://scorpius:elite_password_123@postgres:5432/scorpius_elite
      REDIS_URL: redis://redis:6379
      SMTP_SERVER: ${SMTP_SERVER:-smtp.gmail.com}
      SMTP_PORT: ${SMTP_PORT:-587}
      SMTP_USERNAME: ${SMTP_USERNAME}
      SMTP_PASSWORD: ${SMTP_PASSWORD}
      EMAIL_FROM: ${EMAIL_FROM:-alerts@scorpius.com}
      SLACK_WEBHOOK_URL: ${SLACK_WEBHOOK_URL}
      SLACK_BOT_TOKEN: ${SLACK_BOT_TOKEN}
      DISCORD_WEBHOOK_URL: ${DISCORD_WEBHOOK_URL}
      MAX_NOTIFICATIONS_PER_HOUR: 1000
      MAX_RETRIES: 3
      RETRY_DELAY_SECONDS: 60
    restart: unless-stopped

  time-machine:
    build:
      context: ./services/time_machine
      dockerfile: Dockerfile
    depends_on:
      kafka:
        condition: service_healthy
      postgres:
        condition: service_healthy
    environment:
      KAFKA_BROKERS: kafka:29092
      KAFKA_INPUT_TOPIC: tx_raw
      KAFKA_CONSUMER_GROUP: time-machine-service
      POSTGRES_URL: postgres://scorpius:elite_password_123@postgres:5432/scorpius_elite
      S3_BUCKET: ${S3_BUCKET:-scorpius-mempool-archive}
      S3_REGION: ${S3_REGION:-us-east-1}
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
      ARCHIVE_INTERVAL_HOURS: 1
      BATCH_SIZE: 10000
      COMPRESSION_TYPE: gzip
      ARCHIVE_FORMAT: parquet
      RETENTION_DAYS: 365
      MAX_MEMORY_MB: 2048
      MAX_CONCURRENT_ARCHIVES: 3
    restart: unless-stopped

  # ==================== MONITORING ====================
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
    restart: unless-stopped

  grafana:
    image: grafana/grafana:latest
    ports:
      - "3001:3000"
    environment:
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_PASSWORD:-admin123}
      GF_INSTALL_PLUGINS: grafana-clock-panel,grafana-simple-json-datasource
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./monitoring/grafana/datasources:/etc/grafana/provisioning/datasources
    depends_on:
      - prometheus
    restart: unless-stopped

volumes:
  postgres_data:
  redis_data:
  clickhouse_data:
  prometheus_data:
  grafana_data:
